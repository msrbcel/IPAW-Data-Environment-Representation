\section{Introduction}
In the knowledge economy, large amounts of data are collected to support decision-making, policy analytics and service delivery. However, the utility of these data is constrained by the disclosure risks involved in data processing in general and data sharing in particular. One of the tools used to mitigate this risk,  is anonymisation.  The Anonymisation Decision-Marking Framework (ADF) operationalises the processes of functional anonymisation\cite{elliot2018functional}. 
This conceptualization originated in work of the \textit{data environment analysis service}\cite{elliot2010data}; a support system for the 2011 UK census focused on data confidentiality and  disclosure control \cite[e.g.][]{willenborg2012elements,duncan2011concepts,hundepool2012SDC} and in particular re-identification risk assessment \cite [e.g.][]{chen1998, skinner1998estimating,skinner2002measure}. The critical point underlying the concept is that disclosure risk resides not in the data themselves but in the relationship between the data and their environment.  Mackey and Elliot define the data environment as "the set of formal and informal structures, processes, mechanisms and agents that either: (i) act on data; (ii) provide interpretable context for that data or (iii) define, control and/ or interact with that data" \cite{mackey2013understanding}. Data environments come in a variety of types. For example, the open data environment, an end-user license management data environment, restricted access secure data environments, etc. Notwithstanding this variety, the ADF framework assumes that all data environments can be described through four descriptive features: other data, agents, infrastructure, and governance. 
It follows from the foregoing that in order to apply the appropriate anonymisation processes, one needs to take account of both the data and their environment. Elliot et al. \cite{elliot2020anonymisation} developed the ADF to operationalise exactly such a process. The ADF emphasizes that the appropriate anonymisation decisions about a given set of data are only be possible by considering the relationship between the data and their environment(s) which they call the \textit{data situation}.  Data situations are often \textit{dynamic} in that data moves between environments and so understanding risk, and how to manage that risk through anonymisation, requires an awareness of, and capacity to map, the data flows between environments. 

Currently, the \textit{data situation} capture and mapping for analysis within the ADF framework is done manually, which is labour intensive and prone to possible errors. In order to automate this mapping, we propose the use of data provenance - a concept that is already mentioned in a informal sense in the ADF. By utilizing a machine-interpretable representation of the data, its source and processing, machine enabled reasoning to underpin anonymisation decsion making may become possible. 

By integrating provenance with the ADF, we will be able to track the flows of data and  recognise the upstream and downstream  data situations - both existing and proposed. Data provenance has already been applied in the modelling of similar problems such as  situation awareness and decision making \cite{baclawski2017framework}, controlling of direct and indirect data flows \cite{rong2020provenance}, big data security and privacy \cite{gao2020big}. 

W3C PROV is a standard for provenance interoperability for representing where data came from, and how it has been processed \cite{PROV-DM15,missier2013w3c}. PROV provides an abstract data model that includes agents, entities, activities, and relationship properties and which enables the representation of the  provenance of data and systems.

A critical element in linking provenance to the ADF is the representation of data environments. In the W3C PROV data model, bundles, collections, entities, activities, and agents are all candidates for representing data environments. In this paper, we examine how the elements of PROV (i.e. Entity, Bundle, Agent, Activity) could be used to represent data environment features (agents, other data, infrastructure,  governance). We observe that there are limitations to representing data situations in this way. 

The contributions of this work are as follows:
\begin{enumerate}
    \item We outline using a real ADF use case the requirements for provenance and data environments representation in section \ref{sec:usecase}.
    \item Using these requirements, we propose four different approaches to apply and extend W3C PROV to enable the representation of data environments for machine enabled reasoning in section \ref{sec:impl}.
    \item We then analyze the four approaches in section \ref{sec:analysis}. Realted work is described in section \ref{sec:relwork}, discussion of the implied changes to PROV can be found in section \ref{sec:discussion }
      and finally we outline next steps in section \ref{sec:concl}.
\end{enumerate}

