\section{Related Work} \label{sec:relwork}

%\subsection{Extending W3C PROV}
The W3C PROV has been used to capture provenance to protect data subjects privacy, and security of data. A W3C PROV based provenance model has been proposed by Benjamin et al. \cite{ujcich2018provenance} that uses the PROV data model ontology and data protection ontology to express the provenance for compliance of the European Union (EU) General Data Protection Regulation (GDPR). The Agent, Activity, and Entity classes from the PROV ontology were extended with sub-classes to express the provenance for GDPR compliance. For example, \textit{Subject}, \textit{Controller}, \textit{Processor}, and \textit{Supervising-Authority} sub-classes were introduced within the agent class. The Activity class was extended with  two additional sub-classes: \textit{Process} and \textit{Justify}. Similarly, the Entity class was extended with three sub-classes:  \textit{PersonalData}, \textit{Request} and \textit{Justification}. The relationships among the classes were expressed with PROV properties. Both of the ADF examples presented in this work fall under GDPR regulations, and the extensions introduced in Benjamin et al. \cite{ujcich2018provenance} would facilitate some of the more general requirements of \textbf{Representation of agents, data and processes}and \textbf{contracts} within Data Environments.

To support  provenance of mutable values by time-versioning entities,  a PROV extension has been developed by adding the reference sharing and checkpoints feature \cite{pimentel2018versioned}. These features were built on top of  PROV events that track a version of and object or entity through changes on generation events (i.e. \textit{prov:Generation}) and access in  usage events (i.e. \textit{prov:used  }). The checkpoint attributes were used with the PROV entities, activities, relationship properties for tagging and tracking of changes in the entities over the time period. For this purpose, two Namespaces (i.e. version and script) were created to support the checkpoints mechanism. The version and script Namespaces were used for general PROV extension concepts and specific script concepts. However, this approach increases the extra overhead for querying the provenance graph due to folding and unfolding for adding the checkpoints.  

% \subsection{Using provenance to protect data and systems}
% Data provenance is  applied to detecting intrusion and faults in the operating system kernel environments. For this purpose the CamFlow \cite{pasquier2017practical}  was developed with the notion of "whole system provenance" that
%  detect  attacks by the intruders in the Linux Kernel.  CamFlow captures the provenance features by using  Linux Security Modules (LSM) and NetFilter (NF) hooks. In these features it is recorded that how the information is exchanged through system calls at point in time and in shared state. %For representing the provenance features, the CamFlow's authors have extended W3C PROV Data Model (PROV-DM) \cite{PROV-DM15}.
%  In the captured provenance  the kernel objects such as files, messages, packets, network addresses,  inode attributes, exec parameters have been represented as entities. And system calls and operation processes (e.g. read, write) were represented as activities. For CamFlow's proof of concept, two provenance graphs containing  system state with correct behaviour  and incorrect behaviour were generated in the cloud streaming environment. And finally both provenance graphs were matched through sliding windows technique for the detection of attacks in the streaming. \todo{Aslam, please go look up CamFlow. It may not be w3c, but it is provenance. They (and a few other groups working with them) are using provenance to detect intrusion detection attacks.} \todo[color=green!40]{updated,---   }   

In order to supervise  security of big data streaming, the W3C PROV data model has been extended with a new relationship properties \cite{gao2020big}. These properties focus on  collecting the provenance information about the  data operations inside and outside of big data clusters. It represents the data interaction flow between the clusters. The harvested relationship provenance information of the graph is analysed for the detection of anomalies in the data. The anomaly detection and reasoning mechanism checks any inconsistency among the nodes and edges. To capturing the features for verifying the originality and source of data  received from sensors and edge cloud devices, the data situation can be modelled based on the data provenance . For this purpose, authors \cite{pahl2018architecture}, have used the W3C PROV data model along with the blockchain technology to implement the trust analysis platform. Which perform the trusted orchestration of devices in the edge  IoT environment. Additionally, the W3C PROV has been used to protect the data provenance content that are sensitive  and subject to disclosure control \cite{missier2020abstracting}, modelling the threat of attack to supply chain electronic management system \cite{halak2021cist}, and detection of bottlenecks in the system by analysing the patterns in the provenance graph \cite{boutamina2018bottleneck}.

